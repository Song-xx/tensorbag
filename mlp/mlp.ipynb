{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron\n",
    "=============\n",
    "\n",
    "The Multi Layer Perceptron (MLP) is an extension of the classical [Perceptron](https://en.wikipedia.org/wiki/Perceptron) having one or more hiddel layers. \n",
    "\n",
    "The MLP in is classical form, is based on an input layer, an hidden layer and an output layer. The transfer function used between the layer and in output is a standard Sigmoid. The loss function can be defined as the mean squared error between the output and the labels. Each layer of the MLP can be represetned as a vector-matrix multiplication between an input vector $\\boldsymbol{x}$ and a weight matrix $\\boldsymbol{W}$. The resulting value is added to a bias and passed to an activation function, generating an output vector $\\boldsymbol{y}$. These operations are equivalent to the weighted sum of the input values.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"../etc/img/mlp_model.png\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "It is possible to stack multiple hidden layers into a deep feedforward network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the model in Tensorflow\n",
    "------------------------------------------\n",
    "\n",
    "It is straightforward to implement the model in Tensorflow. Using the `tf.layers` facilities we can define a perceptron in three lines of code. Here I will use the implementation based on the `Estimator` class that requires to embedd the model into a function and associate it to the estimator object. The model is automatically stored in a folder (specified when you create the estimator) and a checkpoint is saved during the training. Thanks to the checkpoint you can resume the training at any time. The output value returned by the MLP is a real number between 0 and 1 given by the sigmoid. The output can be approximated to the closest integer using `tf.round()`. Through the round off it is possible to interpret the results in term of classification and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_model_fn(features, labels, mode):\n",
    "    #Defining the MLP model\n",
    "    x = tf.reshape(features, [-1, 2])\n",
    "    h = tf.layers.dense(inputs=x, units=8, activation=tf.nn.sigmoid)   \n",
    "    y = tf.layers.dense(inputs=h, units=1, activation=tf.nn.sigmoid)\n",
    "    #PREDICT mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\"classes\": tf.round(y),\n",
    "                       \"probabilities\": y}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    #TRAIN mode\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=y)\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=tf.round(y))\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) #<-- accuracy[1] to grab the value\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"accuracy\" : accuracy[1]}, every_n_iter=250)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks =[logging_hook])\n",
    "    #EVAL mode\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=y)\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=tf.round(y))\n",
    "        eval_metric = {\"accuracy\": accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = tf.estimator.Estimator(model_fn=my_model_fn, model_dir=\"./tf_mlp_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "---------------------\n",
    "\n",
    "Once we have the model ready, we can train it on a dataset. Here I will use the **XOR dataset** that has been created in [another notebook](../xor/xor.ipynb) of this repository. You do not have to run the notebook, since a version of the dataset has been included in TensorBag and is ready to be used. With the estimator class of Tensorflow it is necessary to pass an input function to the trainer. Here I define this function and I parse the dataset that is stored in TFRecord format. The dataset is allocated as a Tensorflow `Dataset` object, that makes very easy to return samples from it. Remember that you can monitor the training using **Tensorboard** through the `--logdir` parameter from the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn():  \n",
    "    def _parse_function(example_proto):\n",
    "        features = {\"feature\": tf.VarLenFeature(tf.float32),\n",
    "                    \"label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        feature = tf.cast(parsed_features[\"feature\"], tf.float32)\n",
    "        feature = tf.sparse_tensor_to_dense(feature, default_value=0)\n",
    "        label = tf.reshape(parsed_features[\"label\"], [1])\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        return feature, label\n",
    "\n",
    "    tf_train_dataset = tf.data.TFRecordDataset(\"../xor/xor_train.tfrecord\")\n",
    "    tf_train_dataset = tf_train_dataset.map(_parse_function)\n",
    "    tf_train_dataset.cache() # caches entire dataset\n",
    "    #Setting a buffer_size greater than the number of examples in the Dataset \n",
    "    #ensures that the data is completely shuffled. \n",
    "    tf_train_dataset = tf_train_dataset.shuffle(buffer_size = 8000 * 2) # shuffle all the elements\n",
    "    #The repeat method has the Dataset restart when it reaches the end.\n",
    "    tf_train_dataset = tf_train_dataset.repeat() # repeats dataset this times\n",
    "    #The batch method collects a number of examples and stacks them, to create batches. \n",
    "    #This adds a dimension to their shape. The new dimension is added as the first dimension.\n",
    "    #The batch may have unknown batch size because the last batch can have fewer elements.\n",
    "    tf_train_dataset = tf_train_dataset.batch(32) # batch size\n",
    "    \n",
    "    iterator = tf_train_dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_mlp_model/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into ./tf_mlp_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73025155, step = 5001\n",
      "INFO:tensorflow:accuracy = 0.0\n",
      "INFO:tensorflow:global_step/sec: 850.984\n",
      "INFO:tensorflow:loss = 0.6561349, step = 5101 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1346.59\n",
      "INFO:tensorflow:loss = 0.45106137, step = 5201 (0.075 sec)\n",
      "INFO:tensorflow:accuracy = 0.1953125 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.716\n",
      "INFO:tensorflow:loss = 0.2362873, step = 5301 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 1185.49\n",
      "INFO:tensorflow:loss = 0.29466355, step = 5401 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.129\n",
      "INFO:tensorflow:loss = 0.21783349, step = 5501 (0.572 sec)\n",
      "INFO:tensorflow:accuracy = 0.39732143 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1050.17\n",
      "INFO:tensorflow:loss = 0.14938045, step = 5601 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1303.54\n",
      "INFO:tensorflow:loss = 0.09914072, step = 5701 (0.076 sec)\n",
      "INFO:tensorflow:accuracy = 0.55625 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.979\n",
      "INFO:tensorflow:loss = 0.12422678, step = 5801 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1254.27\n",
      "INFO:tensorflow:loss = 0.104257196, step = 5901 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.241\n",
      "INFO:tensorflow:loss = 0.09429369, step = 6001 (0.577 sec)\n",
      "INFO:tensorflow:accuracy = 0.63461536 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 1265.63\n",
      "INFO:tensorflow:loss = 0.08200896, step = 6101 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1298.47\n",
      "INFO:tensorflow:loss = 0.09741869, step = 6201 (0.076 sec)\n",
      "INFO:tensorflow:accuracy = 0.6875 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.588\n",
      "INFO:tensorflow:loss = 0.05786954, step = 6301 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 1458.6\n",
      "INFO:tensorflow:loss = 0.10288292, step = 6401 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.551\n",
      "INFO:tensorflow:loss = 0.061120637, step = 6501 (0.544 sec)\n",
      "INFO:tensorflow:accuracy = 0.7253289 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 1435.98\n",
      "INFO:tensorflow:loss = 0.06630028, step = 6601 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1399.19\n",
      "INFO:tensorflow:loss = 0.0768324, step = 6701 (0.071 sec)\n",
      "INFO:tensorflow:accuracy = 0.75284094 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.435\n",
      "INFO:tensorflow:loss = 0.11838281, step = 6801 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 1467.37\n",
      "INFO:tensorflow:loss = 0.07517204, step = 6901 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.523\n",
      "INFO:tensorflow:loss = 0.077929795, step = 7001 (0.573 sec)\n",
      "INFO:tensorflow:accuracy = 0.77 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 1370.35\n",
      "INFO:tensorflow:loss = 0.066965245, step = 7101 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1001.43\n",
      "INFO:tensorflow:loss = 0.04884036, step = 7201 (0.102 sec)\n",
      "INFO:tensorflow:accuracy = 0.78683037 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.349\n",
      "INFO:tensorflow:loss = 0.073932566, step = 7301 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 1181.62\n",
      "INFO:tensorflow:loss = 0.101284154, step = 7401 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.138\n",
      "INFO:tensorflow:loss = 0.099410236, step = 7501 (0.581 sec)\n",
      "INFO:tensorflow:accuracy = 0.797379 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 1457.34\n",
      "INFO:tensorflow:loss = 0.06415719, step = 7601 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1685.75\n",
      "INFO:tensorflow:loss = 0.0956685, step = 7701 (0.060 sec)\n",
      "INFO:tensorflow:accuracy = 0.8079044 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.336\n",
      "INFO:tensorflow:loss = 0.053843454, step = 7801 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 1418.93\n",
      "INFO:tensorflow:loss = 0.031600595, step = 7901 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.439\n",
      "INFO:tensorflow:loss = 0.08471951, step = 8001 (0.560 sec)\n",
      "INFO:tensorflow:accuracy = 0.8192568 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 1531.67\n",
      "INFO:tensorflow:loss = 0.066881426, step = 8101 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1486.59\n",
      "INFO:tensorflow:loss = 0.076109245, step = 8201 (0.067 sec)\n",
      "INFO:tensorflow:accuracy = 0.8257812 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.334\n",
      "INFO:tensorflow:loss = 0.09635727, step = 8301 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 1604.28\n",
      "INFO:tensorflow:loss = 0.066950604, step = 8401 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.331\n",
      "INFO:tensorflow:loss = 0.08159036, step = 8501 (0.542 sec)\n",
      "INFO:tensorflow:accuracy = 0.8292151 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 1536.9\n",
      "INFO:tensorflow:loss = 0.084379286, step = 8601 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 1450.47\n",
      "INFO:tensorflow:loss = 0.09317804, step = 8701 (0.069 sec)\n",
      "INFO:tensorflow:accuracy = 0.8308424 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.752\n",
      "INFO:tensorflow:loss = 0.067854315, step = 8801 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 1323.45\n",
      "INFO:tensorflow:loss = 0.046715245, step = 8901 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.162\n",
      "INFO:tensorflow:loss = 0.047982372, step = 9001 (0.577 sec)\n",
      "INFO:tensorflow:accuracy = 0.83864796 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 1363.07\n",
      "INFO:tensorflow:loss = 0.055442356, step = 9101 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1458.35\n",
      "INFO:tensorflow:loss = 0.073387995, step = 9201 (0.067 sec)\n",
      "INFO:tensorflow:accuracy = 0.84314907 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.185\n",
      "INFO:tensorflow:loss = 0.09318437, step = 9301 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 1741.1\n",
      "INFO:tensorflow:loss = 0.037259344, step = 9401 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.98\n",
      "INFO:tensorflow:loss = 0.07898872, step = 9501 (0.578 sec)\n",
      "INFO:tensorflow:accuracy = 0.84659094 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1644.01\n",
      "INFO:tensorflow:loss = 0.04926595, step = 9601 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1463.68\n",
      "INFO:tensorflow:loss = 0.058419265, step = 9701 (0.068 sec)\n",
      "INFO:tensorflow:accuracy = 0.8512931 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.023\n",
      "INFO:tensorflow:loss = 0.0674056, step = 9801 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1583.76\n",
      "INFO:tensorflow:loss = 0.085076466, step = 9901 (0.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ./tf_mlp_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.082412414.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f814a57fd90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.train(input_fn=my_input_fn, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the test set\n",
    "------------------------------\n",
    "\n",
    "The XOR dataset also has a test set that can be used to estimate the accuracy of the MLP. Here we use the `eval()` method of the Tensorflow Estimator class and we pass an input function that pre-process the dataset. The result is in term of loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_eval_input_fn():\n",
    "    def _parse_function(example_proto):\n",
    "        features = {\"feature\": tf.VarLenFeature(tf.float32),\n",
    "                    \"label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        feature = tf.cast(parsed_features[\"feature\"], tf.float32)\n",
    "        feature = tf.sparse_tensor_to_dense(feature, default_value=0)\n",
    "        label = tf.reshape(parsed_features[\"label\"], [1])\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        return feature, label\n",
    "\n",
    "    tf_test_dataset = tf.data.TFRecordDataset(\"../xor/xor_test.tfrecord\")\n",
    "    tf_test_dataset = tf_test_dataset.map(_parse_function)\n",
    "    tf_test_dataset.cache() # caches entire dataset\n",
    "    tf_test_dataset = tf_test_dataset.repeat(1) # repeats dataset this times\n",
    "    tf_test_dataset = tf_test_dataset.batch(1) # batch size  \n",
    "    \n",
    "    iterator_test = tf_test_dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator_test.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-17-19:03:07\n",
      "INFO:tensorflow:Restoring parameters from ./tf_mlp_model/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [200/2000]\n",
      "INFO:tensorflow:Evaluation [400/2000]\n",
      "INFO:tensorflow:Evaluation [600/2000]\n",
      "INFO:tensorflow:Evaluation [800/2000]\n",
      "INFO:tensorflow:Evaluation [1000/2000]\n",
      "INFO:tensorflow:Evaluation [1200/2000]\n",
      "INFO:tensorflow:Evaluation [1400/2000]\n",
      "INFO:tensorflow:Evaluation [1600/2000]\n",
      "INFO:tensorflow:Evaluation [1800/2000]\n",
      "INFO:tensorflow:Evaluation [2000/2000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-19:03:08\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.922, global_step = 10000, loss = 0.06358527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.922, 'global_step': 10000, 'loss': 0.06358527}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(input_fn=my_eval_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model on new data\n",
    "--------------------------------\n",
    "\n",
    "To use the model on custom data it is possible to use the `predict()` method of the estimator class. Also in this case an input function must be used in order to return the input features. You may need the truth table of the XOR operator:\n",
    "\n",
    "- 1 XOR 1 = 0\n",
    "- 1 XOR 0 = 1\n",
    "- 0 XOR 1 = 1\n",
    "- 0 XOR 0 = 0\n",
    "\n",
    "When the input values are equal (same sign) the output is False (zero). When the input values are different, the output is True (one). Here I hardcoded some values that belong to the four quadrants of the XOR plane. The output is printed on the terminal and should be: zero, one, one, zero. You can also try different values and ve the output from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_predict_input_fn():\n",
    "    feture_batch = tf.constant([[3.5, 2.9], [3.5, -2.9], [-3.5, 2.9], [-3.5, -2.9]])\n",
    "    \n",
    "    tf_predict_dataset = tf.data.Dataset.from_tensor_slices((feture_batch))\n",
    "    tf_predict_dataset = tf_predict_dataset.repeat(1)\n",
    "    \n",
    "    iterator_predict = tf_predict_dataset.make_one_shot_iterator()\n",
    "    batch_features = iterator_predict.get_next()\n",
    "    return batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_mlp_model/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [0.]\n",
      "Probabilities: [0.18594189]\n",
      "\n",
      "Predicted class: [1.]\n",
      "Probabilities: [0.86161345]\n",
      "\n",
      "Predicted class: [1.]\n",
      "Probabilities: [0.83655787]\n",
      "\n",
      "Predicted class: [0.]\n",
      "Probabilities: [0.13499346]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(input_fn=my_predict_input_fn)\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print \"Predicted class: \" + str(prediction['classes'])\n",
    "    print \"Probabilities: \" + str(prediction['probabilities'])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
